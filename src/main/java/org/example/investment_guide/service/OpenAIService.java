package org.example.investment_guide.service;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.example.investment_guide.dto.BaseLLMResponse;
import org.example.investment_guide.common.ModelType;
import org.example.investment_guide.dto.OpenAIAPIParam;
import org.example.investment_guide.repository.OpenAIRepository;
import org.example.investment_guide.util.PromptFactory;
import java.util.logging.Logger;

public class OpenAIService {
    private static final OpenAIService instance = new OpenAIService();
    private final ObjectMapper objectMapper = new ObjectMapper();
    private final OpenAIRepository repository = OpenAIRepository.getInstance();
    private static final Logger logger = Logger.getLogger(OpenAIService.class.getName());

    private OpenAIService() {}

    public static OpenAIService getInstance() {
        return instance;
    }

    /**
     * OpenAI ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ë©”ì„œë“œ
     * @param prompt ìœ ì € ì§ˆë¬¸
     * @param modelType ì‚¬ìš©í•  ëª¨ë¸ íƒ€ì… (Base, Reasoning)
     * @return OpenAI LLMì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
     * @throws JsonProcessingException JSON íŒŒì‹± ì˜ˆì™¸
     */
    public String useModel(String prompt, ModelType modelType) throws JsonProcessingException {
        logger.info("ğŸŸ¢ OpenAIService.useModel() ì‹¤í–‰ë¨");
        logger.info("ğŸ“Œ ì…ë ¥ í”„ë¡¬í”„íŠ¸: " + prompt);
        logger.info("ğŸ“Œ ëª¨ë¸ íƒ€ì…: " + modelType);

        // âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± (PromptFactory ì‚¬ìš©)
        String processedPrompt = modelType == ModelType.BASE
                ? PromptFactory.generatePrompt(prompt, modelType)  // gpt-4-turbo
                : "[Advanced Analysis Mode]\n" + PromptFactory.generatePrompt(prompt, modelType);  // gpt-4

        // âœ… OpenAI API í˜¸ì¶œ
        String responseText = repository.callAPI(new OpenAIAPIParam(processedPrompt, modelType));

        logger.info("âœ… OpenAI API ì‘ë‹µ ë°›ìŒ: " + responseText);

        BaseLLMResponse llmResponse = objectMapper.readValue(responseText, BaseLLMResponse.class);

        if (llmResponse.choices() == null || llmResponse.choices().isEmpty()) {
            logger.severe("âŒ OpenAI API ì‘ë‹µ ì˜¤ë¥˜: choicesê°€ ë¹„ì–´ ìˆìŒ.");
            return "âŒ AIê°€ ìœ íš¨í•œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.";
        }

        return llmResponse.choices().get(0).message().content();
    }

    public String useBaseModel(String prompt) throws JsonProcessingException {
        return useModel(prompt, ModelType.BASE);
    }

    public String useReasoningModel(String prompt) throws JsonProcessingException {
        return useModel(prompt, ModelType.REASONING);
    }
}
